{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5564309a-edad-4281-809c-e6b363eb34ba",
   "metadata": {},
   "source": [
    "# A4: Political Bias\n",
    "In this assignment, you will be trying to calculate the average political bias and reliability of posts on Bluesky.\n",
    "\n",
    "The code you are starting with here already does a search on a Bluesky and finds the reliability and political bias of url web addresses posted there. You will need to add loop variables to calculate these averages (see chapter 8 practice and demos).\n",
    "\n",
    "After you get the averages to work, you wll then try your code with other search terms, and then you will answer some reflection questions.\n",
    "\n",
    "First, we'll do our normal Bluesky login steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20296f2f-5dfe-4001-b5ed-bc2c44baa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from atproto import Client\n",
    "%run bluesky_keys.py\n",
    "client = Client(base_url=\"https://bsky.social\")\n",
    "client.login(handle, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a83f21-2fb4-4500-a75b-838f93e9fbfb",
   "metadata": {},
   "source": [
    "## Load Bias and Reliability Info\n",
    "\n",
    "The code below saves some bias and reliability values. You can look at the code below you are interested, but you are not required to.\n",
    "\n",
    "The part you need to know is that the measures of website bias and reliability are based on the [Media Bias Chart](https://adfontesmedia.com/) (old version 9.0). We took their ratings of reliability and bias and simplified them into a scale with bias ranging from -4 (extremely liberal) to +4 (extremely conservative), and reliability from +2 (fact reporting) to -4 (fabricated or inaccurate). We then chose a few of the more common websites to let us look up info. \n",
    "![Media bias chart with grid, showing the range labels](./imgs/bias_chart_divisions.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c63cb1-ef90-451a-8f4b-953d4ffe2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code saves bias and reliability info in lookup dictionaries\n",
    "# for different websites.\n",
    "# If you want to, you can update the values to make\n",
    "# them match the current chart, or you can add additional\n",
    "# sites to the data (just make sure you add it to both\n",
    "# the bias and reliability dictionaries)\n",
    "media_bias_lookup = {\n",
    "    \"pbs.org\": -1,\n",
    "    \"apnews.com\": -1,\n",
    "    \"reuters.com\": -1,\n",
    "    \"abc.com\": -1,\n",
    "    \"abcnews.go.com\": -1,\n",
    "    \"bbc.co.uk\": -1,\n",
    "    \"bbc.com\": -1,\n",
    "    \"npr.org\": -1,\n",
    "    \"cnn.com\": -2,\n",
    "    \"wsj.com\": 1,\n",
    "    \"nbc.com\": -2,\n",
    "    \"nbcnews.com\": -2,\n",
    "    \"nytimes.com\": -2,\n",
    "    \"theguardian.com\": -2,\n",
    "    \"washingtonpost.com\": -2,\n",
    "    \"vice.com\": -2,\n",
    "    \"vox.com\": -2,\n",
    "    \"usatoday.com\": -1,\n",
    "    \"rasmussenreports.com\": 2,\n",
    "    \"huffpost.com\": -2,\n",
    "    \"msnbc.com\": -2,\n",
    "    \"newrepublic.com\": -3,\n",
    "    \"salon.com\": -3,\n",
    "    \"theweek.com\": -2,\n",
    "    \"freebeacon.com\": 2,\n",
    "    \"foxnews.com\": 2,\n",
    "    \"reason.com\": 2,\n",
    "    \"nypost.com\": 2,\n",
    "    \"dailywere.com\": 2,\n",
    "    \"nationalreview.com\": 2,\n",
    "    \"theblaze.com\": 2,\n",
    "    \"dailykos.com\": -3,\n",
    "    \"wsws.org\": -3,\n",
    "    \"tyt.com\": -3,\n",
    "    \"distractify.com\": -2,\n",
    "    \"bipartisanreport.com\": -3,\n",
    "    \"hartmannreport.com\": -3,\n",
    "    \"palmerreport.com\": -1,\n",
    "    \"vetarnstoday.com\": -2,\n",
    "    \"dailymail.co.uk\": 1,\n",
    "    \"dailycaller.com\": 2,\n",
    "    \"breitbart.com\": 2,\n",
    "    \"newsmax.com\": 2,\n",
    "    \"oann.com\": 2,\n",
    "    \"aclj.org\": 2,\n",
    "    \"tpusa.com\": 2,\n",
    "    \"infowars.com\": 3\n",
    "}\n",
    "\n",
    "media_reliability_lookup = {\n",
    "    \"pbs.org\": 2,\n",
    "    \"apnews.com\": 2,\n",
    "    \"reuters.com\": 2,\n",
    "    \"abc.com\": 1,\n",
    "    \"abcnews.go.com\": 1,\n",
    "    \"bbc.co.uk\": 1,\n",
    "    \"bbc.com\": 1,\n",
    "    \"npr.org\": 1,\n",
    "    \"cnn.com\": 1,\n",
    "    \"wsj.com\": 1,\n",
    "    \"nbc.com\": 1,\n",
    "    \"nbcnews.com\": 1,\n",
    "    \"nytimes.com\": 1,\n",
    "    \"theguardian.com\": 1,\n",
    "    \"washingtonpost.com\": 1,\n",
    "    \"wapo\": 1,\n",
    "    \"vice.com\": 1,\n",
    "    \"vox.com\": 1,\n",
    "    \"usatoday.com\": 1,\n",
    "    \"rasmussenreports.com\": 1,\n",
    "    \"huffpost.com\": 0,\n",
    "    \"msnbc.com\": 0,\n",
    "    \"newrepublic.com\": 0,\n",
    "    \"salon.com\": 0,\n",
    "    \"theweek.com\": 0,\n",
    "    \"freebeacon.com\": 0,\n",
    "    \"foxnews.com\": 0,\n",
    "    \"reason.com\": 0,\n",
    "    \"nypost.com\": 0,\n",
    "    \"dailywere.com\": 0,\n",
    "    \"nationalreview.com\": 0,\n",
    "    \"theblaze.com\": 0,\n",
    "    \"dailykos.com\": -1,\n",
    "    \"wsws.org\": -1,\n",
    "    \"tyt.com\": -1,\n",
    "    \"distractify.com\": -1,\n",
    "    \"bipartisanreport.com\": -1,\n",
    "    \"hartmannreport.com\": -1,\n",
    "    \"palmerreport.com\": -1,\n",
    "    \"vetarnstoday.com\": -2,\n",
    "    \"dailymail.co.uk\": -1,\n",
    "    \"dailycaller.com\": -1,\n",
    "    \"breitbart.com\": -1,\n",
    "    \"newsmax.com\": -1,\n",
    "    \"oann.com\": -1,\n",
    "    \"aclj.org\": -2,\n",
    "    \"tpusa.com\": -2,\n",
    "    \"infowars.com\": -3\n",
    "}\n",
    "\n",
    "def find_matching_site(url):\n",
    "    for site in media_sites:\n",
    "        if site in url:\n",
    "            return site   \n",
    "\n",
    "media_sites = media_bias_lookup.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdcebaf-89d8-4c9c-b8c4-d9e439174036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper function will help us look up full urls, since some posts come with shortened ones\n",
    "# It has a bunch of checks to timeout on DNS connections and reads, and tries 3 times to find the URL\n",
    "# If it fails, it just gives up and gives you the short url\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_full_url(short_url, timeout=(2, 5), retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.head(short_url, allow_redirects=True, timeout=timeout)\n",
    "            return response.url\n",
    "        except requests.Timeout:\n",
    "            print(f\"Timeout on attempt {attempt + 1} for URL: {short_url}\")\n",
    "            if attempt < retries - 1:\n",
    "                sleep(1)  # Optional: wait before retrying\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error retrieving URL: {e}\")\n",
    "            return short_url\n",
    "    return short_url  # Return the original if all attempts fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80d8af-cbe6-411d-af71-a22663677660",
   "metadata": {},
   "source": [
    "## Get a list of search results from Bluesky\n",
    "\n",
    "We will now get a list of results from Bluesky. To start with, we'll try to get 100 with the search term \"Seattle.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2646c223-c803-4789-b450-0d796e1d2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"params\" variable is what we send as a search request to bluesky\n",
    "# 'q' is the search query; edit this if you want to try different search terms\n",
    "# 'limit' is the maximum number of posts you'll extract. \n",
    "params = {\n",
    "        'q': \"Seattle\",\n",
    "        'limit': 100\n",
    "    }\n",
    "\n",
    "posts = client.app.bsky.feed.search_posts(params=params)['posts']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26f615-2d7a-4c52-87f5-89aebe4ca70e",
   "metadata": {},
   "source": [
    "## TODO: Modify the code below (Run Search)\n",
    "The code below loops through each bluesky post, and if the submission was a website url, the program checks to see if we have reliability/bias info on the site. If we have that info we calculate the bias and reliability and display it.\n",
    "\n",
    "__Your job__ is to add loop variables to the code to calculate the number of urls we had info for (`number_matched_urls`) and then the total bias and total reliability for those urls. Then you can use that at the end to calculate the average bias and average reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469136b4-3f9f-4370-88c8-c00c5ad86207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: Create your loop variables here\n",
    "\n",
    "# Go through all the posts\n",
    "for p in posts:\n",
    "    embed = p['record']['embed']\n",
    "    \n",
    "    # Check if the post has an external link\n",
    "    if hasattr(embed, 'external') and hasattr(embed['external'], 'uri'):\n",
    "        url = embed['external']['uri']\n",
    "\n",
    "        #Need to check if we can find the full url, so our lookup is more accurate\n",
    "        #Note \n",
    "        print(\"Checking for full url...\")\n",
    "        full_url = get_full_url(url)\n",
    "        print(full_url)\n",
    "        # try to find the source website in our dataset\n",
    "        matching_site = find_matching_site(full_url)\n",
    "\n",
    "         # if we found the matching site, then we have info for it\n",
    "        if(matching_site):\n",
    "            \n",
    "            # look up the bias and reliability for the site the url is from\n",
    "            url_bias = media_bias_lookup[matching_site]\n",
    "            url_reliability = media_reliability_lookup[matching_site]\n",
    "\n",
    "            #### TODO: Update the three loop variables here #### \n",
    "\n",
    "            print(\"  bias: \" + str(url_bias))\n",
    "            print(\"  reliability: \" + str(url_reliability))\n",
    "        else:\n",
    "            # We didn't have info on this site\n",
    "            print(\"**did not recognize site!\")\n",
    "\n",
    "#### TODO: calculate the averages below and output the total and averages\n",
    "# Note: It's ok if the code gives an error when no urls are found\n",
    "#  (since trying to find the average might cause a divide by 0 error)    \n",
    "\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Total number of urls we could measure: \")\n",
    "print(\"Average bias: \")\n",
    "print(\"Average reliability: \")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63eaa6-fbb8-4208-ba24-d999a87df650",
   "metadata": {},
   "source": [
    "## Reflection tasks\n",
    "\n",
    "Once you get the code above working and finding an average bias and reliability, modify the search to try at least three different searches. Open up the bluesky separately and try the same searches look at your results, then answer the questions below.\n",
    "\n",
    "Note: For searches, you can search try different search terms that might have different views and post links to news articles, like: \"news\", \"science\", \"politics\", \"liberal\", \"conservative\", \"tech\", \"BlackLivesMatter\", etc.\n",
    "\n",
    "1. What additional searches did you run (at least 3)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089734b0-d861-4be2-a394-062905f011b5",
   "metadata": {},
   "source": [
    "TODO: Answer question here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471a9632-bf36-496e-9c83-16e894906333",
   "metadata": {},
   "source": [
    "2. When doing those searches, what were your observations about the calculations of media bias and reliability? (For example: were there a lot of urls that you didn't measure? Do you feel like the final calculated bias and reliability match the search results?). Answer with at least 3 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d23fc-bbc6-41c7-a1fb-04539b2bd531",
   "metadata": {},
   "source": [
    "TODO: Answer question here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a876e-41f8-4f1d-917a-9dd1a952311c",
   "metadata": {},
   "source": [
    "3. If you could redesign the Media Bias Chart, what would you want to do (e.g., add some other dimension besides just bias/responsibility like other [Political Spectrums](https://en.wikipedia.org/wiki/Political_spectrum), change how it is evaluated, add more news sources, consider different countries)? Answer with at least 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d13a6-24be-449c-8cb4-7dcaa58d02da",
   "metadata": {},
   "source": [
    "TODO: Answer question here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e583bb-cbc4-4a90-aed6-cf5deca55e88",
   "metadata": {},
   "source": [
    "4. What might a social media companies or advertizers (including political campaigns) want to do with information on a users' political views and susceptibility to consipracy theories? Answer with at least 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de3bf3-04d6-4bb0-ae1e-3d072e0940e0",
   "metadata": {},
   "source": [
    "TODO: Answer question here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e22fe8-3f80-4138-9eae-f2517de835b9",
   "metadata": {},
   "source": [
    "5. Choose two ethics frameworks and use the frameworks to consider the different uses of the media bias and reliability information. Answer with at least 6 sentences total (e.g., 3 per framework)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d1e3b",
   "metadata": {},
   "source": [
    "TODO: Answer question here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
